{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD Brand List of Shopinng Mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from playwright.async_api import Page\n",
    "from components.dev.shop.shop_product_card_list.schema import ListConfig, ListScrapData\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from components.dev.shop.shop_list.parent_class import PwShopList\n",
    "\n",
    "class PwAfewStoreList(PwShopList):\n",
    "    def __name__(self) -> str:\n",
    "        return \"a_few_store\"\n",
    "\n",
    "    def config(self) -> ListConfig:\n",
    "        return ListConfig(\n",
    "            scroll_on=True,\n",
    "            reverse_not_found_result=True,\n",
    "            page_reload_after_cookies=False,\n",
    "            not_found_xpath='//div[contains(@class,\"findify-components-search--lazy-results\")]',\n",
    "            wait_until_load=10000,\n",
    "        )\n",
    "\n",
    "    async def extract_card_html(self, page: Page) -> List[Tag] | None:\n",
    "        product_cards = await page.query_selector(\n",
    "            '//div[contains(@class,\"findify-components-search--lazy-results\")]'\n",
    "        )\n",
    "        if product_cards:\n",
    "            cards = await product_cards.inner_html()\n",
    "            cards = BeautifulSoup(cards, \"html.parser\")\n",
    "            cards = cards.find_all({\"attrs\": {\"class\": \"product-card\"}})\n",
    "            assert cards, \"load_product_card : No product cards found\"\n",
    "            return cards\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def extract_info(self, card: Tag) -> ListScrapData:\n",
    "        price = card.find(class_=\"price\").text  # type: ignore\n",
    "        id = card[\"id\"].replace(\"findify_\", \"\")  # type: ignore\n",
    "\n",
    "        return ListScrapData(\n",
    "            shop_product_name=card.img[\"data-src\"].split(\"/\")[-1],  # type: ignore\n",
    "            shop_product_img_url=card.img[\"src\"],  # type: ignore\n",
    "            product_url=card[\"href\"],  # type: ignore\n",
    "            product_id=id,\n",
    "            price=price,\n",
    "        )\n",
    "\n",
    "    async def get_next_page(self, page: Page, page_num: int) -> bool:\n",
    "        xpath = \"//button[contains(@class,'findify-components--button btn btn-outline-dark')]\"\n",
    "        button = await page.query_selector(xpath)\n",
    "\n",
    "        if not button:\n",
    "            return False\n",
    "\n",
    "        await button.click()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'components/dev/cookie/cookies.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshop_product_card_list\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlist_scraper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShopListScrapMachine\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbrowser_controller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PwBrowserController\n\u001b[0;32m----> 3\u001b[0m browser_controller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m PwBrowserController()\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m      4\u001b[0m page_controller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m browser_controller\u001b[38;5;241m.\u001b[39mcreate_page_controller()\n\u001b[1;32m      5\u001b[0m module \u001b[38;5;241m=\u001b[39m PwAfewStoreList()\n",
      "File \u001b[0;32m~/repo/captured/admin/backend/test/playwright/../../components/dev/utils/browser_controller/__init__.py:140\u001b[0m, in \u001b[0;36mPwBrowserController.create\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_pw()\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/repo/captured/admin/backend/test/playwright/../../components/dev/utils/browser_controller/__init__.py:149\u001b[0m, in \u001b[0;36mPwBrowserController.init_pw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pw\u001b[38;5;241m.\u001b[39mfirefox\u001b[38;5;241m.\u001b[39mlaunch(headless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser\u001b[38;5;241m.\u001b[39mnew_context()\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cookies()\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\n",
      "File \u001b[0;32m~/repo/captured/admin/backend/test/playwright/../../components/dev/utils/browser_controller/__init__.py:158\u001b[0m, in \u001b[0;36mPwBrowserController.load_cookies\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cookies\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    157\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents/dev\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookie\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookies.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    159\u001b[0m         cookies \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(file\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39madd_cookies(cookies)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'components/dev/cookie/cookies.json'"
     ]
    }
   ],
   "source": [
    "from components.dev.shop.shop_product_card_list.list_scraper import ShopListScrapMachine\n",
    "from components.dev.utils.browser_controller import PwBrowserController\n",
    "browser_controller = await PwBrowserController().create()\n",
    "page_controller = await browser_controller.create_page_controller()\n",
    "module = PwAfewStoreList()\n",
    "\n",
    "scraper = ShopListScrapMachine(page_controller,module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../router/dev/kream/cookie/cookies.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Set cookies in the current page\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39madd_cookies(cookies)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m load_cookies(page)\n",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mload_cookies\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cookies\u001b[39m(page):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Load cookies from a file or database\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# In this example, cookies are loaded from a file named 'cookies.json'\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../router/dev/kream/cookie/cookies.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     30\u001b[0m         cookies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(file\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Set cookies in the current page\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../router/dev/kream/cookie/cookies.json'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any, Callable\n",
    "\n",
    "import asyncio \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import expect, async_playwright, Page, TimeoutError as PlaywrightTimeoutError \n",
    "\n",
    "\n",
    "\n",
    "pw = await async_playwright().start()\n",
    "browser = await pw.firefox.launch(headless=False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "\n",
    "page.set_default_timeout(15000)\n",
    "\n",
    "async def _load_page( page: Page, url):\n",
    "    \"\"\"페이지 로드\"\"\"\n",
    "    await asyncio.sleep(1)\n",
    "    await page.goto(url)\n",
    "    await page.wait_for_load_state(state=\"networkidle\")\n",
    "    await page.wait_for_timeout(1000)\n",
    "    return page\n",
    "\n",
    "async def load_cookies(page):\n",
    "    # Load cookies from a file or database\n",
    "    # In this example, cookies are loaded from a file named 'cookies.json'\n",
    "    \n",
    "    with open('../../router/dev/kream/cookie/cookies.json', 'r') as file:\n",
    "        cookies = eval(file.read())\n",
    "\n",
    "    # Set cookies in the current page\n",
    "    await page.context.add_cookies(cookies)\n",
    "\n",
    "await load_cookies(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[{'shop_product_size': 'ONE SIZE', 'kor_product_size': 'ONE SIZE'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'X000006756020416'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.sevenstore.com/accessories/hats-gloves/arcteryx-blue-tetra-bird-head-toque/\"\n",
    "\n",
    "await page.goto(url,wait_until='domcontentloaded',timeout=10000)\n",
    "\n",
    "async def get_size_info(page: Page) -> List[Dict[str, Any]]:\n",
    "        locator = page.locator(\".product-sizes-title\")\n",
    "        await expect(locator).to_have_text(\"Sizes\", timeout=10000)\n",
    "        # await expect(page.get_by_text(\"Sizes\")).to_be_visible(timeout=10000)\n",
    "\n",
    "        size_query = await page.query_selector_all(\n",
    "            '//div[contains(@class, \"size-wrapper\")]',\n",
    "        )\n",
    "\n",
    "        size_list = [await s.inner_text() for s in size_query]\n",
    "\n",
    "        if not size_list:\n",
    "            return [{\"shop_product_size\": \"-\", \"kor_product_size\": \"-\"}]\n",
    "\n",
    "        l = []\n",
    "        for s in size_list:\n",
    "            kor_size = s\n",
    "            try:\n",
    "                if float(s) < 15:\n",
    "                    kor_size = \"UK \" + s\n",
    "            except:\n",
    "                pass\n",
    "            l.append({\"shop_product_size\": s, \"kor_product_size\": kor_size})\n",
    "\n",
    "        return l\n",
    "\n",
    "async def get_product_id(page) -> str:\n",
    "    product_id_text = await page.query_selector(\n",
    "        '//meta[contains(@name, \"description\")]',\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        product_id_text = await product_id_text.get_attribute(\"content\")\n",
    "        product_id = product_id_text.split(\":\")[1].replace(\" \", \"\")\n",
    "    except:\n",
    "        product_id = \"-\"\n",
    "\n",
    "    return product_id.upper()\n",
    "\n",
    "\n",
    "print(await get_size_info(page))\n",
    "\n",
    "await get_product_id(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_text = await page.query_selector('//*[@id=\"detailsPanel\"]/div')\n",
    "product_id_text = await product_id_text.inner_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = product_id_text.lower()\n",
    "if \"product code\" in text :\n",
    "    product_id = text.split(\"product code\")[1].strip()\n",
    "else:\n",
    "    product_id = '-'\n",
    "\n",
    "product_id.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await _load_page(page, \"https://kream.co.kr/login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_cookies(page):\n",
    "    # Get cookies from the current page\n",
    "    cookies = await page.context.cookies()\n",
    "\n",
    "    # Save cookies to a file or database\n",
    "    # In this example, cookies are saved to a file named 'cookies.json'\n",
    "    with open('../../router/dev/kream/cookie/cookies.json', 'w') as file:\n",
    "        file.write(str(cookies))\n",
    "\n",
    "await save_cookies(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_cookies(page):\n",
    "    # Load cookies from a file or database\n",
    "    # In this example, cookies are loaded from a file named 'cookies.json'\n",
    "    \n",
    "    with open('../../router/dev/kream/cookie/cookies.json', 'r') as file:\n",
    "        cookies = eval(file.read())\n",
    "\n",
    "    # Set cookies in the current page\n",
    "    await page.context.add_cookies(cookies)\n",
    "\n",
    "await load_cookies(page)\n",
    "await page.goto(\"https://kream.co.kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = await page.query_selector(\".wish_count_num\")\n",
    "brand = await brand.inner_text()\n",
    "int(brand.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = await page.query_selector_all(\".body_list\")\n",
    "volumes = [BeautifulSoup(await i.inner_html()) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _extract_volume_data_from(body_list: List) -> List[List]:\n",
    "#     \"\"\"\n",
    "#     크롤링 결과 리스트에서 거래량 추출\n",
    "\n",
    "#     Args:\n",
    "#         body_list (List): 크롤링 결과 리스트\n",
    "\n",
    "#     Returns:\n",
    "#         List: 크롤링 결과 리스트로 반환\n",
    "#     \"\"\"\n",
    "\n",
    "#     def preprocess_items(tags) -> List:\n",
    "#         l = []\n",
    "#         for tag in tags.find_all(class_=\"list_txt\"):\n",
    "#             l.append(tag.text.lstrip().rstrip())\n",
    "\n",
    "#         if \"빠른\" in l[1]:\n",
    "#             l = l[:1] + l[1].split(\" \")[:1] + [True] + l[2:3].replace(\"빠른배송\", \"\").strip()\n",
    "#         else:\n",
    "#             l = l[:2] + [False] + l[2:3].replace(\"빠른배송\", \"\").strip()\n",
    "#         return l\n",
    "\n",
    "#     return [preprocess_items(tags) for tags in body_list]\n",
    "\n",
    "# body_list = _extract_volume_data_from(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = await page.query_selector_all(\".body_list\")\n",
    "volumes = [BeautifulSoup(await i.inner_html()) for i in x]\n",
    "\n",
    "\n",
    "def _extract_volume_data_from(body_list: List) -> List[List]:\n",
    "    \"\"\"\n",
    "    크롤링 결과 리스트에서 거래량 추출\n",
    "\n",
    "    Args:\n",
    "        body_list (List): 크롤링 결과 리스트\n",
    "\n",
    "    Returns:\n",
    "        List: 크롤링 결과 리스트로 반환\n",
    "    \"\"\"\n",
    "\n",
    "    def preprocess_items(tags) -> List:\n",
    "        x = []\n",
    "        for tag in tags.find_all(class_=\"list_txt\"):\n",
    "            x.append(tag.text.strip())\n",
    "        if \"빠\"in x[1] :\n",
    "            return [x[0], x[1], True, x[2].replace('빠른배송','').strip()]\n",
    "        else :\n",
    "            return [x[0], x[1], False, x[2].replace('빠른배송','').strip()]\n",
    "\n",
    "    return [preprocess_items(tags) for tags in body_list]\n",
    "\n",
    "body_list = _extract_volume_data_from(volumes)\n",
    "body_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
